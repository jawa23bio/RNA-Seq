---
title: "Week 1 Notebook"
output: html_document
---


Do your best to write in the style of a scientific publication.
We will spend some time in class discussing some general conventions
and guidelines for scientific writing. 

# Write your methods for this week in the following space:
The raw FASTQ files obtained from the experiment were subjected to quality control using the FastQC bioinformatics tool. 
The Snakemake workflow was set up to execute FastQC on each of the 16 FASTQ files, representing eight samples with two replicates each.

All the FASTQ files were initially called as sample_data using expand function. Input, Output and param details were provided accordingly and 
fastqc was executed on the sample fastq files. The resulting fastqc files were stored in the 'results/' directory.

Following the individual FastQC analyses, the MultiQC utility was employed to aggregate and summarize the results into a comprehensive report. 
Input for MultiQC analysis is the fastqc files present in the '/results' directory. 
The MultiQC tool was configured to search for FastQC output files in the 'results/' directory and generate a consolidated report 'multiqc_report' and 
the results from MultiQC was reverted back to '/results' directory.

# Write your results for this week in the following space:
The results of the FastQC analyses were examined individually for each sample and replicate. Every sample had the same sequence length and had approximately 50% GC content.
Other quality metrics, such as per-base sequence quality, sequence length distribution, and overrepresented sequences were also reported for each of the samples and replicates.

The MultiQC report was generated by consolidating the individual FastQC outputs. Some of the key highlights of the MultiQC report were:
Phred scores were consistent amongst all the samples. P7rep2subsample_R1 had a higher GC content of 60%. 14 out of the 16 samples had an overrepresented sequences by sample ratio.

```{r, if you need any code blocks, you can instantiate them like this}


```


# Conceptual Questions

In this repo, in the docs section, we have provided you with a multiQC report
generated from the full data run with the same tools as you have. Compare the
report **you** generated from the subsampled data to the provided report.

1. When comparing the two reports, which modules appear to be most influenced by 
    the size of the files? Which modules show consistent results?

Sequence Counts module seems to be very different since the number of duplicate reads in the our report had approximately 1000 reads but whereas the provided multiQC report
shows read counts in millions. Overrepresented sequences are much larger in the generated report whereas in the provided multiQC report, 
it had less than 1% overrepresented sequences in the 16 sample files.


2. Look at the **full** report, you'll notice that the duplication rates for the
    P0, P4, and P7 samples appear to be relatively close together (~50%). The 
    duplication rates for the AD samples appear to be much higher. Provide at least
    one biological and one technical reason that might explain these results. Can you
    describe how you might confirm your provided explanations. 

Biological Reason:
Biological Variation in Genome Complexity: The discrepancy in duplication rates could be attributed to inherent differences in the biological samples. 
The AD samples might possess a more complex genome with repetitive elements, leading to higher duplication rates. 
These repetitive regions can be challenging for sequencing technologies, resulting in increased duplication.

Technical Reason:
Library Preparation Artifacts: Technical factors during library preparation might contribute to the variation. 
Issues like uneven DNA fragmentation or PCR bias can introduce artifacts, especially in complex samples. 
The AD samples might be more prone to these technical challenges, resulting in elevated duplication rates.

Confirmation Strategies:

1. Biological Validation:

Conduct a more in-depth analysis of the genomic features of the AD samples. 
Employ techniques like PCR followed by Sanger sequencing to explore repetitive elements or regions with higher complexity.

Perform additional assays, such as chromatin immunoprecipitation sequencing (ChIP-seq), to investigate specific genomic regions that could contribute to higher duplication rates.


2. Technical Validation:

Re-run the library preparation for the AD samples, paying careful attention to factors that might introduce biases. 
Optimize DNA fragmentation protocols and PCR conditions to minimize technical artifacts.

Use alternative library preparation methods or sequencing platforms to assess whether the observed duplication rates persist across different methodologies.
